{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb8242a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95b4434b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Downsample1d(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(dim, dim, 3, 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class Upsample1d(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.conv = nn.ConvTranspose1d(dim, dim, 4, 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b19b00b",
   "metadata": {},
   "source": [
    "#### Downsample Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad2d81f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a (torch.Size([1, 8])):\n",
      "tensor([[0., 1., 2., 3., 4., 5., 6., 7.]])\n",
      "Downsampled output (torch.Size([1, 4])):\n",
      "tensor([[-0.6217, -0.6218, -0.1521,  0.3176]], grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# Example input:\n",
    "a = torch.arange(0, 8, dtype=torch.float32).view(1, -1) # Add batch dimension\n",
    "print(f\"a ({a.shape}):\\n{a}\")\n",
    "\n",
    "# Output of Downsample1d:\n",
    "downsample_1d = Downsample1d(dim=len(a))\n",
    "downsample_out = downsample_1d(a)\n",
    "\n",
    "print(f\"Downsampled output ({downsample_out.shape}):\\n{downsample_out}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8d9b40",
   "metadata": {},
   "source": [
    "#### Upsample Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2130d500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a (torch.Size([1, 4])):\n",
      "tensor([[0., 1., 2., 3.]])\n",
      "Upsampled output (torch.Size([1, 8])):\n",
      "tensor([[-0.3003, -0.1834,  0.0246, -0.2721,  0.1318, -0.3607,  0.2389, -0.9170]],\n",
      "       grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# Example input:\n",
    "a = torch.arange(0, 4, dtype=torch.float32).view(1, -1) # Add batch dimension\n",
    "print(f\"a ({a.shape}):\\n{a}\")\n",
    "\n",
    "# Output of Downsample1d:\n",
    "upsample_1d = Upsample1d(dim=len(a))\n",
    "upsample_out = upsample_1d(a)\n",
    "\n",
    "print(f\"Upsampled output ({upsample_out.shape}):\\n{upsample_out}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
